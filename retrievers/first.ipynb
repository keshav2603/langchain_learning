{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538ab34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6c2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3cad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=WikipediaRetriever(top_k_results=2,lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329d157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "querry=\"tell me about the difference between ai engineer and ml engineer\"\n",
    "\n",
    "docs=retriever.invoke(querry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8965b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Explainable artificial intelligence', 'summary': 'Within artificial intelligence (AI), explainable AI (XAI), generally overlapping with interpretable AI or explainable machine learning (XML), is a field of research that explores methods that provide humans with the ability of intellectual oversight over AI algorithms. The main focus is on the reasoning behind the decisions or predictions made by the AI algorithms, to make them more understandable and transparent. This addresses users\\' requirement to assess safety and scrutinize the automated decision making in applications. XAI counters the \"black box\" tendency of machine learning, where even the AI\\'s designers cannot explain why it arrived at a specific decision.\\nXAI hopes to help users of AI-powered systems perform more effectively by improving their understanding of how those systems reason. XAI may be an implementation of the social right to explanation. Even if there is no such legal right or regulatory requirement, XAI can improve the user experience of a product or service by helping end users trust that the AI is making good decisions. XAI aims to explain what has been done, what is being done, and what will be done next, and to unveil which information these actions are based on. This makes it possible to confirm existing knowledge, challenge existing knowledge, and generate new assumptions.', 'source': 'https://en.wikipedia.org/wiki/Explainable_artificial_intelligence'}, page_content='Within artificial intelligence (AI), explainable AI (XAI), generally overlapping with interpretable AI or explainable machine learning (XML), is a field of research that explores methods that provide humans with the ability of intellectual oversight over AI algorithms. The main focus is on the reasoning behind the decisions or predictions made by the AI algorithms, to make them more understandable and transparent. This addresses users\\' requirement to assess safety and scrutinize the automated decision making in applications. XAI counters the \"black box\" tendency of machine learning, where even the AI\\'s designers cannot explain why it arrived at a specific decision.\\nXAI hopes to help users of AI-powered systems perform more effectively by improving their understanding of how those systems reason. XAI may be an implementation of the social right to explanation. Even if there is no such legal right or regulatory requirement, XAI can improve the user experience of a product or service by helping end users trust that the AI is making good decisions. XAI aims to explain what has been done, what is being done, and what will be done next, and to unveil which information these actions are based on. This makes it possible to confirm existing knowledge, challenge existing knowledge, and generate new assumptions.\\n\\n\\n== Background ==\\nMachine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts. XAI algorithms follow the three principles of transparency, interpretability, and explainability.\\n\\nA model is transparent \"if the processes that extract model parameters from training data and generate labels from testing data can be described and motivated by the approach designer.\"\\nInterpretability describes the possibility of comprehending the ML model and presenting the underlying basis for decision-making in a way that is understandable to humans.\\nExplainability is a concept that is recognized as important, but a consensus definition is not yet available; one possibility is \"the collection of features of the interpretable domain that have contributed, for a given example, to producing a decision (e.g., classification or regression)\".\\nIn summary, Interpretability refers to the user\\'s ability to understand model outputs, while Model Transparency includes Simulatability (reproducibility of predictions), Decomposability (intuitive explanations for parameters), and Algorithmic Transparency (explaining how algorithms work). Model Functionality focuses on textual descriptions, visualization, and local explanations, which clarify specific outputs or instances rather than entire models. All these concepts aim to enhance the comprehensibility and usability of AI systems.\\nIf algorithms fulfill these principles, they provide a basis for justifying decisions, tracking them and thereby verifying them, improving the algorithms, and exploring new facts.\\nSometimes it is also possible to achieve a high-accuracy result with white-box ML algorithms. These algorithms have an interpretable structure that can be used to explain predictions. Concept Bottleneck Models, which use concept-level abstractions to explain model reasoning, are examples of this and can be applied in both image and text prediction tasks. This is especially important in domains like medicine, defense, finance, and law, where it is crucial to understand decisions and build trust in the algorithms. Many researchers argue that, at least for supervised machine learning, the way forward is symbolic regression, where the algorithm searches the space of mathematical expressions to find the model that best fits a given dataset.\\nAI systems optimize behavior to satisfy a mathematically specified goal system chosen by the system designers, such as the command \"maximize the accuracy o'),\n",
       " Document(metadata={'title': 'Chatbot', 'summary': 'A chatbot (originally chatterbot) is a software application or web interface designed to have textual or spoken conversations. Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing. Simpler chatbots have existed for decades.\\nChatbots have gained popularity with the release of ChatGPT in 2022, followed by competitors such as Gemini, Claude, and Grok, in what is labelled an AI boom. AI chatbots typically use fine-tuned large language models to generate text.\\nA major area where chatbots have long been used is customer service and support, with various sorts of virtual assistants.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Chatbot'}, page_content='A chatbot (originally chatterbot) is a software application or web interface designed to have textual or spoken conversations. Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing. Simpler chatbots have existed for decades.\\nChatbots have gained popularity with the release of ChatGPT in 2022, followed by competitors such as Gemini, Claude, and Grok, in what is labelled an AI boom. AI chatbots typically use fine-tuned large language models to generate text.\\nA major area where chatbots have long been used is customer service and support, with various sorts of virtual assistants.\\n\\n\\n== History ==\\n\\n\\n=== Turing test ===\\nIn 1950, Alan Turing published an article entitled \"Computing Machinery and Intelligence\" in which he proposed what is now called the Turing test as a criterion of intelligence. This criterion depends on the ability of a computer program to impersonate a human in a real-time written conversation with a human judge, to the extent that the judge is incapable of reliably distinguishing, on the basis of the conversational content alone, between the program and a real human.\\n\\n\\n=== Early chatbots ===\\nJoseph Weizenbaum\\'s program ELIZA was first published in 1966. Weizenbaum did not claim that ELIZA was genuinely intelligent, and the introduction to his paper presented it more as a debunking exercise:In artificial intelligence, machines are made to behave in wondrous ways, often sufficient to dazzle even the most experienced observer. But once a particular program is unmasked, once its inner workings are explained, its magic crumbles away; it stands revealed as a mere collection of procedures. The observer says to himself \"I could have written that\". With that thought, he moves the program in question from the shelf marked \"intelligent\", to that reserved for curios. The object of this paper is to cause just such a re-evaluation of the program about to be \"explained\". Few programs ever needed it more. ELIZA\\'s key method of operation involves the recognition of clue words or phrases in the input, and the output of the corresponding pre-prepared or pre-programmed responses that can move the conversation forward in an apparently meaningful way (e.g. by responding to any input that contains the word \\'MOTHER\\' with \\'TELL ME MORE ABOUT YOUR FAMILY\\'). Thus an illusion of understanding is generated, even though the processing involved has been merely superficial. ELIZA showed that such an illusion is surprisingly easy to generate because human judges are ready to give the benefit of the doubt when conversational responses are capable of being interpreted as \"intelligent\".\\nFollowing ELIZA, psychiatrist Kenneth Colby developed PARRY in 1972.\\nFrom 1978 to some time after 1983, the CYRUS project led by Janet Kolodner constructed a chatbot simulating Cyrus Vance (57th United States Secretary of State). It used case-based reasoning, and updated its database daily by parsing wire news from United Press International. The program was unable to process the news items subsequent to the surprise resignation of Cyrus Vance in April 1980, and the team constructed another chatbot simulating his successor, Edmund Muskie.\\nIn 1984, an interactive version of the program Racter was released which acted as a chatbot.\\nA.L.I.C.E. was released in 1995. This uses a markup language called AIML, which is specific to its function as a conversational agent, and has since been adopted by various other developers of, so-called, Alicebots. A.L.I.C.E. is a weak AI without any reasoning capabilities. It is based on a similar pattern matching technique as ELIZA in 1966. This is not strong AI, which would require sapience and logical reasoning abilities.\\nJabberwacky, released in 1997, learns new responses and context ')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e96b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------result 1----------\n",
      "\n",
      "Within artificial intelligence (AI), explainable AI (XAI), generally overlapping with interpretable AI or explainable machine learning (XML), is a field of research that explores methods that provide humans with the ability of intellectual oversight over AI algorithms. The main focus is on the reasoning behind the decisions or predictions made by the AI algorithms, to make them more understandable and transparent. This addresses users' requirement to assess safety and scrutinize the automated decision making in applications. XAI counters the \"black box\" tendency of machine learning, where even the AI's designers cannot explain why it arrived at a specific decision.\n",
      "XAI hopes to help users of AI-powered systems perform more effectively by improving their understanding of how those systems reason. XAI may be an implementation of the social right to explanation. Even if there is no such legal right or regulatory requirement, XAI can improve the user experience of a product or service by helping end users trust that the AI is making good decisions. XAI aims to explain what has been done, what is being done, and what will be done next, and to unveil which information these actions are based on. This makes it possible to confirm existing knowledge, challenge existing knowledge, and generate new assumptions.\n",
      "\n",
      "\n",
      "== Background ==\n",
      "Machine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts. XAI algorithms follow the three principles of transparency, interpretability, and explainability.\n",
      "\n",
      "A model is transparent \"if the processes that extract model parameters from training data and generate labels from testing data can be described and motivated by the approach designer.\"\n",
      "Interpretability describes the possibility of comprehending the ML model and presenting the underlying basis for decision-making in a way that is understandable to humans.\n",
      "Explainability is a concept that is recognized as important, but a consensus definition is not yet available; one possibility is \"the collection of features of the interpretable domain that have contributed, for a given example, to producing a decision (e.g., classification or regression)\".\n",
      "In summary, Interpretability refers to the user's ability to understand model outputs, while Model Transparency includes Simulatability (reproducibility of predictions), Decomposability (intuitive explanations for parameters), and Algorithmic Transparency (explaining how algorithms work). Model Functionality focuses on textual descriptions, visualization, and local explanations, which clarify specific outputs or instances rather than entire models. All these concepts aim to enhance the comprehensibility and usability of AI systems.\n",
      "If algorithms fulfill these principles, they provide a basis for justifying decisions, tracking them and thereby verifying them, improving the algorithms, and exploring new facts.\n",
      "Sometimes it is also possible to achieve a high-accuracy result with white-box ML algorithms. These algorithms have an interpretable structure that can be used to explain predictions. Concept Bottleneck Models, which use concept-level abstractions to explain model reasoning, are examples of this and can be applied in both image and text prediction tasks. This is especially important in domains like medicine, defense, finance, and law, where it is crucial to understand decisions and build trust in the algorithms. Many researchers argue that, at least for supervised machine learning, the way forward is symbolic regression, where the algorithm searches the space of mathematical expressions to find the model that best fits a given dataset.\n",
      "AI systems optimize behavior to satisfy a mathematically specified goal system chosen by the system designers, such as the command \"maximize the accuracy o\n",
      "\n",
      "----------result 2----------\n",
      "\n",
      "A chatbot (originally chatterbot) is a software application or web interface designed to have textual or spoken conversations. Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing. Simpler chatbots have existed for decades.\n",
      "Chatbots have gained popularity with the release of ChatGPT in 2022, followed by competitors such as Gemini, Claude, and Grok, in what is labelled an AI boom. AI chatbots typically use fine-tuned large language models to generate text.\n",
      "A major area where chatbots have long been used is customer service and support, with various sorts of virtual assistants.\n",
      "\n",
      "\n",
      "== History ==\n",
      "\n",
      "\n",
      "=== Turing test ===\n",
      "In 1950, Alan Turing published an article entitled \"Computing Machinery and Intelligence\" in which he proposed what is now called the Turing test as a criterion of intelligence. This criterion depends on the ability of a computer program to impersonate a human in a real-time written conversation with a human judge, to the extent that the judge is incapable of reliably distinguishing, on the basis of the conversational content alone, between the program and a real human.\n",
      "\n",
      "\n",
      "=== Early chatbots ===\n",
      "Joseph Weizenbaum's program ELIZA was first published in 1966. Weizenbaum did not claim that ELIZA was genuinely intelligent, and the introduction to his paper presented it more as a debunking exercise:In artificial intelligence, machines are made to behave in wondrous ways, often sufficient to dazzle even the most experienced observer. But once a particular program is unmasked, once its inner workings are explained, its magic crumbles away; it stands revealed as a mere collection of procedures. The observer says to himself \"I could have written that\". With that thought, he moves the program in question from the shelf marked \"intelligent\", to that reserved for curios. The object of this paper is to cause just such a re-evaluation of the program about to be \"explained\". Few programs ever needed it more. ELIZA's key method of operation involves the recognition of clue words or phrases in the input, and the output of the corresponding pre-prepared or pre-programmed responses that can move the conversation forward in an apparently meaningful way (e.g. by responding to any input that contains the word 'MOTHER' with 'TELL ME MORE ABOUT YOUR FAMILY'). Thus an illusion of understanding is generated, even though the processing involved has been merely superficial. ELIZA showed that such an illusion is surprisingly easy to generate because human judges are ready to give the benefit of the doubt when conversational responses are capable of being interpreted as \"intelligent\".\n",
      "Following ELIZA, psychiatrist Kenneth Colby developed PARRY in 1972.\n",
      "From 1978 to some time after 1983, the CYRUS project led by Janet Kolodner constructed a chatbot simulating Cyrus Vance (57th United States Secretary of State). It used case-based reasoning, and updated its database daily by parsing wire news from United Press International. The program was unable to process the news items subsequent to the surprise resignation of Cyrus Vance in April 1980, and the team constructed another chatbot simulating his successor, Edmund Muskie.\n",
      "In 1984, an interactive version of the program Racter was released which acted as a chatbot.\n",
      "A.L.I.C.E. was released in 1995. This uses a markup language called AIML, which is specific to its function as a conversational agent, and has since been adopted by various other developers of, so-called, Alicebots. A.L.I.C.E. is a weak AI without any reasoning capabilities. It is based on a similar pattern matching technique as ELIZA in 1966. This is not strong AI, which would require sapience and logical reasoning abilities.\n",
      "Jabberwacky, released in 1997, learns new responses and context \n"
     ]
    }
   ],
   "source": [
    "for i , doc in enumerate(docs):\n",
    "    print(\"\\n\"+\"-\"*10+f\"result {i+1}\"+ \"-\"*10+\"\\n\")\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557968bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "539700b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db25e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store= Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding,\n",
    "    collection_name=\"my_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f325b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever1=vector_store.as_retriever(search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e765d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "querry=\"what is chroma used for\"\n",
    "result=retriever1.invoke(querry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b88e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Chroma is a vector database optimized for LLM-based search.'),\n",
       " Document(metadata={}, page_content='LangChain helps developers build LLM applications easily.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69ed92",
   "metadata": {},
   "source": [
    "### MMR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28175494",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=\"LangChain makes it easy to work with LLMs.\"),\n",
    "    Document(page_content=\"LangChain is used to build LLM based applications.\"),\n",
    "    Document(page_content=\"Chroma is used to store and search document embeddings.\"),\n",
    "    Document(page_content=\"Embeddings are vector representations of text.\"),\n",
    "    Document(page_content=\"MMR helps you get diverse results when doing similarity search.\"),\n",
    "    Document(page_content=\"LangChain supports Chroma, FAISS, Pinecone, and more.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f97bd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "face2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store= Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding,\n",
    "    collection_name=\"my_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "544d4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\":2,\"lambda_mult\":0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00ac22a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='LangChain supports Chroma, FAISS, Pinecone, and more.'),\n",
       " Document(metadata={}, page_content='Embeddings convert text into high-dimensional vectors.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querry=\"what is langchian ?\"\n",
    "retriever.invoke(querry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36a528e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "llm=HuggingFaceEndpoint(\n",
    "    repo_id=\"katanemo/Arch-Router-1.5B\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "model=ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5163fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fe9db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant health & wellness documents\n",
    "all_docs = [\n",
    "    Document(page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
    "    Document(page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity.\", metadata={\"source\": \"H2\"}),\n",
    "    Document(page_content=\"Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
    "    Document(page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
    "    Document(page_content=\"Drinking sufficient water throughout the day helps maintain metabolism and energy.\", metadata={\"source\": \"H5\"}),\n",
    "    Document(page_content=\"The solar energy system in modern homes helps balance electricity demand.\", metadata={\"source\": \"I1\"}),\n",
    "    Document(page_content=\"Python balances readability with power, making it a popular system design language.\", metadata={\"source\": \"I2\"}),\n",
    "    Document(page_content=\"Photosynthesis enables plants to produce energy by converting sunlight.\", metadata={\"source\": \"I3\"}),\n",
    "    Document(page_content=\"The 2022 FIFA World Cup was held in Qatar and drew global energy and excitement.\", metadata={\"source\": \"I4\"}),\n",
    "    Document(page_content=\"Black holes bend spacetime and store immense gravitational energy.\", metadata={\"source\": \"I5\"}),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59036bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store=Chroma.from_documents(documents=all_docs,embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_querry=MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\":2})\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
